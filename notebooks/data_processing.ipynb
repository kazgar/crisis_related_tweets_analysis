{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "\n",
    "from tweet_classification.constants import DATA_PATH\n",
    "from tweet_classification.utils import read_en_humanitarian_data as read_human_data\n",
    "from tweet_classification.utils import read_en_informativeness_data as read_info_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    text = re.sub(r\"rt\\s+\", \"\", text)\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    if text.startswith(\": \"):\n",
    "        text = text[2:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Humanitarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_train_df, human_dev_df, human_test_df = read_human_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels_to_nrs = {\n",
    "    label: i for i, label in enumerate(human_train_df[\"class_label\"].unique().tolist())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_train_df[\"text\"] = human_train_df[\"text\"].apply(clean_text)\n",
    "human_train_df[\"class_label\"] = human_train_df[\"class_label\"].apply(\n",
    "    lambda x: human_labels_to_nrs[x]\n",
    ")\n",
    "human_train_df = human_train_df[[\"text\", \"class_label\"]]\n",
    "\n",
    "human_dev_df[\"text\"] = human_dev_df[\"text\"].apply(clean_text)\n",
    "human_dev_df[\"class_label\"] = human_dev_df[\"class_label\"].apply(lambda x: human_labels_to_nrs[x])\n",
    "human_dev_df = human_dev_df[[\"text\", \"class_label\"]]\n",
    "\n",
    "human_test_df[\"text\"] = human_test_df[\"text\"].apply(clean_text)\n",
    "human_test_df[\"class_label\"] = human_test_df[\"class_label\"].apply(lambda x: human_labels_to_nrs[x])\n",
    "human_test_df = human_test_df[[\"text\", \"class_label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Informativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_train_df, info_dev_df, info_test_df = read_info_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_labels_to_nrs = {\n",
    "    label: i for i, label in enumerate(info_train_df[\"class_label\"].unique().tolist())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_train_df[\"text\"] = info_train_df[\"text\"].apply(clean_text)\n",
    "info_train_df[\"class_label\"] = info_train_df[\"class_label\"].apply(lambda x: info_labels_to_nrs[x])\n",
    "info_train_df = info_train_df[[\"text\", \"class_label\"]]\n",
    "\n",
    "info_dev_df[\"text\"] = info_dev_df[\"text\"].apply(clean_text)\n",
    "info_dev_df[\"class_label\"] = info_dev_df[\"class_label\"].apply(lambda x: info_labels_to_nrs[x])\n",
    "info_dev_df = info_dev_df[[\"text\", \"class_label\"]]\n",
    "\n",
    "info_test_df[\"text\"] = info_test_df[\"text\"].apply(clean_text)\n",
    "info_test_df[\"class_label\"] = info_test_df[\"class_label\"].apply(lambda x: info_labels_to_nrs[x])\n",
    "info_test_df = info_test_df[[\"text\", \"class_label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Save Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "CLEAN_DATA_PATH = DATA_PATH / \"clean_en_data\"\n",
    "\n",
    "os.makedirs(CLEAN_DATA_PATH, exist_ok=True)\n",
    "\n",
    "for human_df, split in zip([human_train_df, human_dev_df, human_test_df], splits):\n",
    "    human_df.to_csv(CLEAN_DATA_PATH / f\"human_{split}.csv\", index=False)\n",
    "\n",
    "for info_df, split in zip([info_train_df, info_dev_df, info_test_df], splits):\n",
    "    info_df.to_csv(CLEAN_DATA_PATH / f\"info_{split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
